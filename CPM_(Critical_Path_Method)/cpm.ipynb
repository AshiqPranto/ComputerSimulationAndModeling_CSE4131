{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Node class to store all the information about a specific node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, node_name, duration) -> None:\n",
    "        # self.node_id = node_id\n",
    "        self.node_name = node_name\n",
    "        self.duration = duration\n",
    "        self.predecessors = []\n",
    "        self.successors = []\n",
    "        self.es = 0; self.ef = 0\n",
    "        self.ls = 0; self.lf = 0\n",
    "        self.sl = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take input from the file and create a graph of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"input.txt\"\n",
    "nodes = {} # a dictionary to store all the information of a nodes against it's name\n",
    "names = [] # al list to store all the node name\n",
    "\n",
    "i = 0\n",
    "for line in open(file_name):\n",
    "    words = line.rstrip().split(' ')\n",
    "    name = words[0]\n",
    "    duration = int(words[1])\n",
    "    nodes[name] = Node(name, duration)\n",
    "    names.append(name)\n",
    "    if(len(words) <= 2):\n",
    "        continue\n",
    "    predecessors = words[2].split(',')\n",
    "    for predecessor in predecessors:\n",
    "        # print(f\"_{predecessor}_\")\n",
    "        nodes[name].predecessors.append(predecessor)\n",
    "        nodes[predecessor].successors.append(name)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iteration of Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ef_among_all_nodes = 0\n",
    "for name in names:\n",
    "    # print(f\"name = {name}\")\n",
    "    if(len(nodes[name].predecessors) == 0):\n",
    "        nodes[name].ef = nodes[name].duration\n",
    "    else:\n",
    "        max_es_among_pre = 0\n",
    "        for predecessor in nodes[name].predecessors:\n",
    "            max_es_among_pre = max(max_es_among_pre, nodes[predecessor].ef)\n",
    "        nodes[name].es = max_es_among_pre\n",
    "        nodes[name].ef = max_es_among_pre + nodes[name].duration\n",
    "    max_ef_among_all_nodes = max(max_ef_among_all_nodes, nodes[name].ef)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iteration of Backward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in reversed(names):\n",
    "    if(len(nodes[name].successors) == 0):\n",
    "        nodes[name].lf = max_ef_among_all_nodes\n",
    "        nodes[name].ls = max_ef_among_all_nodes - nodes[name].duration\n",
    "    else:\n",
    "        min_ls_among_suc = 10 ** 9\n",
    "        for successor in nodes[name].successors:\n",
    "            min_ls_among_suc = min(min_ls_among_suc, nodes[successor].ls)\n",
    "        nodes[name].lf = min_ls_among_suc\n",
    "        nodes[name].ls = min_ls_among_suc - nodes[name].duration\n",
    "        nodes[name].sl = nodes[name].ls - nodes[name].es\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Critical Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A -> ES: 0, EF: 3, LS: 0, LF: 3, slack time: 0\n",
      "B -> ES: 3, EF: 7, LS: 3, LF: 7, slack time: 0\n",
      "C -> ES: 3, EF: 5, LS: 9, LF: 11, slack time: 6\n",
      "D -> ES: 7, EF: 12, LS: 7, LF: 12, slack time: 0\n",
      "E -> ES: 5, EF: 6, LS: 11, LF: 12, slack time: 6\n",
      "F -> ES: 5, EF: 7, LS: 14, LF: 16, slack time: 9\n",
      "G -> ES: 12, EF: 16, LS: 12, LF: 16, slack time: 0\n",
      "H -> ES: 16, EF: 19, LS: 16, LF: 19, slack time: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critical_path = []\n",
    "for name in names:\n",
    "    print(f\"{name} -> ES: {nodes[name].es}, EF: {nodes[name].ef}, LS: {nodes[name].ls}, LF: {nodes[name].lf}, slack time: {nodes[name].sl}\")\n",
    "    if(nodes[name].sl == 0):\n",
    "        critical_path.append(name)\n",
    "# print(critical_path)\n",
    "file = open(\"output.txt\", \"w\")\n",
    "file.write(\"\\n\".join(critical_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
